{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLCourse.ai Kaggle Competition In Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Baseline\n",
    "\n",
    "Objective: Rapidly make a training and testing pipeline. Will only develop functions to clean/standardize data, train a model and return test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 237824\r\n",
      "     0 drwxr-xr-x  8 ns  staff       256  9 Apr 23:33 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "     0 drwxr-xr-x  4 ns  staff       128  9 Apr 23:23 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      " 53248 -rw-r--r--  1 ns  staff  26743371  9 Apr 23:29 catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2.zip\r\n",
      "  2408 -rwxr-xr-x  1 ns  staff   1230867 28 Nov 13:13 \u001b[31msample_submission.csv\u001b[m\u001b[m\r\n",
      "  3520 -rwxr-xr-x  1 ns  staff   1800682 28 Nov 13:13 \u001b[31msite_dic.pkl\u001b[m\u001b[m\r\n",
      " 37992 -rwxr-xr-x  1 ns  staff  19450729 28 Nov 13:13 \u001b[31mtest_sessions.csv\u001b[m\u001b[m\r\n",
      " 22432 -rwxr-xr-x  1 ns  staff  11483103 28 Nov 13:13 \u001b[31mtrain.zip\u001b[m\u001b[m\r\n",
      "118224 -rwxr-xr-x  1 ns  staff  60526801 28 Nov 13:14 \u001b[31mtrain_sessions.csv\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lsa ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>718</td>\n",
       "      <td>2014-02-20 10:02:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>890</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>941.0</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>941.0</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>942.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>3846.0</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>2014-02-22 11:20:15</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>2014-02-22 11:20:16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14769</td>\n",
       "      <td>2013-12-16 16:40:17</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2013-12-16 16:40:18</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>14769.0</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:20</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:21</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:22</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>782</td>\n",
       "      <td>2014-03-28 10:52:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:52:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:53:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:53:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-28 10:54:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:55:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:55:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:56:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:56:42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>2014-02-28 10:53:05</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:55:22</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2014-02-28 10:55:22</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2014-02-28 10:55:23</td>\n",
       "      <td>177.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:57:06</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2014-02-28 10:57:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  site1                time1  site2                time2  \\\n",
       "0           1    718  2014-02-20 10:02:45    NaN                  NaN   \n",
       "1           2    890  2014-02-22 11:19:50  941.0  2014-02-22 11:19:50   \n",
       "2           3  14769  2013-12-16 16:40:17   39.0  2013-12-16 16:40:18   \n",
       "3           4    782  2014-03-28 10:52:12  782.0  2014-03-28 10:52:42   \n",
       "4           5     22  2014-02-28 10:53:05  177.0  2014-02-28 10:55:22   \n",
       "\n",
       "     site3                time3    site4                time4  site5  ...  \\\n",
       "0      NaN                  NaN      NaN                  NaN    NaN  ...   \n",
       "1   3847.0  2014-02-22 11:19:51    941.0  2014-02-22 11:19:51  942.0  ...   \n",
       "2  14768.0  2013-12-16 16:40:19  14769.0  2013-12-16 16:40:19   37.0  ...   \n",
       "3    782.0  2014-03-28 10:53:12    782.0  2014-03-28 10:53:42  782.0  ...   \n",
       "4    175.0  2014-02-28 10:55:22    178.0  2014-02-28 10:55:23  177.0  ...   \n",
       "\n",
       "                 time6    site7                time7    site8  \\\n",
       "0                  NaN      NaN                  NaN      NaN   \n",
       "1  2014-02-22 11:19:51   3847.0  2014-02-22 11:19:52   3846.0   \n",
       "2  2013-12-16 16:40:19  14768.0  2013-12-16 16:40:20  14768.0   \n",
       "3  2014-03-28 10:54:42    782.0  2014-03-28 10:55:12    782.0   \n",
       "4  2014-02-28 10:55:59    175.0  2014-02-28 10:55:59    177.0   \n",
       "\n",
       "                 time8    site9                time9   site10  \\\n",
       "0                  NaN      NaN                  NaN      NaN   \n",
       "1  2014-02-22 11:19:52   1516.0  2014-02-22 11:20:15   1518.0   \n",
       "2  2013-12-16 16:40:21  14768.0  2013-12-16 16:40:22  14768.0   \n",
       "3  2014-03-28 10:55:42    782.0  2014-03-28 10:56:12    782.0   \n",
       "4  2014-02-28 10:55:59    177.0  2014-02-28 10:57:06    178.0   \n",
       "\n",
       "                time10  target  \n",
       "0                  NaN       0  \n",
       "1  2014-02-22 11:20:16       0  \n",
       "2  2013-12-16 16:40:24       0  \n",
       "3  2014-03-28 10:56:42       0  \n",
       "4  2014-02-28 10:57:11       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in training data\n",
    "data = pd.read_csv('../data/train_sessions.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "www.abmecatronique.com                25075\n",
       "groups.live.com                       13997\n",
       "majeureliguefootball.wordpress.com    42436\n",
       "cdt46.media.tourinsoft.eu             30911\n",
       "www.hdwallpapers.eu                    8104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in site dictionary\n",
    "sites = pd.Series(pd.read_pickle('../data/site_dic.pkl'))\n",
    "sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of sites in the set and the unique sites is equal? True\n"
     ]
    }
   ],
   "source": [
    "#Are sites unique?\n",
    "print(f'Names of sites in the set and the unique sites is equal? {len(sites.index.unique()) == len(sites)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253561 entries, 0 to 253560\n",
      "Data columns (total 22 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   session_id  253561 non-null  int64  \n",
      " 1   site1       253561 non-null  int64  \n",
      " 2   time1       253561 non-null  object \n",
      " 3   site2       250098 non-null  float64\n",
      " 4   time2       250098 non-null  object \n",
      " 5   site3       246919 non-null  float64\n",
      " 6   time3       246919 non-null  object \n",
      " 7   site4       244321 non-null  float64\n",
      " 8   time4       244321 non-null  object \n",
      " 9   site5       241829 non-null  float64\n",
      " 10  time5       241829 non-null  object \n",
      " 11  site6       239495 non-null  float64\n",
      " 12  time6       239495 non-null  object \n",
      " 13  site7       237297 non-null  float64\n",
      " 14  time7       237297 non-null  object \n",
      " 15  site8       235224 non-null  float64\n",
      " 16  time8       235224 non-null  object \n",
      " 17  site9       233084 non-null  float64\n",
      " 18  time9       233084 non-null  object \n",
      " 19  site10      231052 non-null  float64\n",
      " 20  time10      231052 non-null  object \n",
      " 21  target      253561 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(10)\n",
      "memory usage: 42.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#investigate data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id    0.000000\n",
       "site1         0.000000\n",
       "time1         0.000000\n",
       "site2         0.013657\n",
       "time2         0.013657\n",
       "site3         0.026195\n",
       "time3         0.026195\n",
       "site4         0.036441\n",
       "time4         0.036441\n",
       "site5         0.046269\n",
       "time5         0.046269\n",
       "site6         0.055474\n",
       "time6         0.055474\n",
       "site7         0.064142\n",
       "time7         0.064142\n",
       "site8         0.072318\n",
       "time8         0.072318\n",
       "site9         0.080758\n",
       "time9         0.080758\n",
       "site10        0.088772\n",
       "time10        0.088772\n",
       "target        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pct nan in the dataset\n",
    "data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc Auc Train: 0.5\n",
      "Roc Auc Test: 0.5\n"
     ]
    }
   ],
   "source": [
    "def clean_data(data):\n",
    "    data = data.fillna(0)\n",
    "    return data\n",
    "\n",
    "def create_features():\n",
    "    pass\n",
    "    \n",
    "def split_data(data, cols=None):\n",
    "    \n",
    "    X = data[cols].astype('int')\n",
    "    Y = data['target']\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "def train_model(x, y, C=0.7, solver='lbfgs'):\n",
    "    clf = LogisticRegression(C=C, solver=solver, random_state=42, n_jobs=4).fit(x, y)\n",
    "    return clf\n",
    "\n",
    "def evaluate_model(model, x, y_true):\n",
    "    result = model.predict(x)\n",
    "    return roc_auc_score(y_true, result)\n",
    "    \n",
    "\n",
    "df = clean_data(data)\n",
    "    \n",
    "sites = [f'site{i}' for i in range(1,11)]\n",
    "\n",
    "train_x, test_x, train_y, test_y = split_data(df, cols=sites)\n",
    "\n",
    "model = train_model(train_x, train_y, C=0.9)\n",
    "\n",
    "roc_train = evaluate_model(model, train_x, train_y)\n",
    "roc_test = evaluate_model(model, test_x, test_y)\n",
    "\n",
    "\n",
    "print(f'Roc Auc Train: {roc_train}')\n",
    "print(f'Roc Auc Test: {roc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Baseline Summary\n",
    "\n",
    "What have we achieved? \n",
    "- In terms of results the predictions are random. The model is unable to learn anything. The question now becomes  *what insights can we derive from the data to learn from* because on a naive baiss the model does not learn.\n",
    "- We have a simple pipeline to run and evaluate the model. GOOD! This makes us quicker to get through iterating ideas.\n",
    "\n",
    "What have we ignored?\n",
    "- We assumed that the site information held some feature that correlated to the target. We have no attepted to create a feature that correlates with this.\n",
    "- We have ignored balancing the dataset for target variables.\n",
    "- We have ignored the information encoded in the timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Site Frequency Feature\n",
    "\n",
    "One assumption we can make is that the more often a site is visited the more likely we can identify the visitor. We can use countvectorizer for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try count vectorizer on the site integer data cast as a string\n",
    "df = clean_data(data[sites])\n",
    "df = df.astype('str')\n",
    "X = CountVectorizer().fit_transform(df)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21       13874\n",
       "23        9244\n",
       "782       7769\n",
       "29        5501\n",
       "22        5434\n",
       "         ...  \n",
       "33159        1\n",
       "34619        1\n",
       "24379        1\n",
       "21552        1\n",
       "21734        1\n",
       "Name: site1, Length: 15765, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the result above is wrong. We should see multiple counts per site. \n",
    "#Therefore we need a different method to get the counts.\n",
    "df['site1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
